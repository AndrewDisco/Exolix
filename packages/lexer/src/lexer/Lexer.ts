import { Buffer } from "node:buffer";
import Token from "../token/Token";
import TokenStructure from "../token/TokenStructure";

/**
 * A lexer is a programmatic tool which analyzes a string, once finished, it can
 * manipulate the tokens, return them, and more.
 */
export default class Lexer<Structure extends TokenStructure> {
    /**
     * The input data of the lexer.
     */
    readonly input: string;

    /**
     * All the analyzed tokens from the lexical analyzer.
     */
    #tokens: Token<Structure>[] = [];

    /**
     * The token tree.
     */
    readonly tree: Structure;

    /**
     * Create a new lexical analyzer.
     *
     * @param tree The token regexp structure tree.
     * @param input The input data for the lexer.
     */
    public constructor(tree: Structure, input: string | Buffer) {
        this.input = input.toString();
        this.tree = tree;

        this.#compileTokens();
    }

    /**
     * Run through with the lexer and generate a token list.
     */
    #compileTokens() {
        let operations = 0;

        let indexStat = 0;
        let lineStat = 0;
        let columnStat = 0;

        let indexPrev = 0;
        let linePrev = 0;
        let columnPrev = 0;

        const perform = (input: string) => {
            operations++;

            let matchRegExpItem: keyof Structure | undefined;
            let passOverInput = input;
            let value = "";

            indexPrev = indexStat;
            linePrev = lineStat;
            columnPrev = columnStat;

            Object.keys(this.tree).forEach((key, index) => {
                if (matchRegExpItem) return;

                const regexp = new RegExp(this.tree[key]);
                const match = regexp.exec(input);

                if (match) {
                    passOverInput = input.slice(match[0].length);
                    matchRegExpItem = key;
                    value = match[0];

                    lineStat += passOverInput.split("\n").length - 1;
                    columnStat = passOverInput.length - passOverInput.split("\n").pop()!.length;

                    if (match[0].includes("\n")) {
                        lineStat++;
                        columnStat = 0;
                    }

                    indexStat += match[0].length;
                }
            });

            if (typeof matchRegExpItem === "undefined") {
                return; // TODO: throw error
            }

            const token: Token<Structure> = {
                lineStart: linePrev,
                lineEnd: lineStat,
                columnStart: columnPrev,
                columnEnd: columnStat,
                type: matchRegExpItem,
                end: indexStat,
                start: indexPrev,
                value,
            };

            this.#tokens.push(token);

            if (passOverInput.length !== input.length) {
                perform(passOverInput);
            }
        }

        perform(this.input);
    }

    /**
     * The tokens that were generated by the lexer.
     */
    public get tokens(): Token<Structure>[] {
        return this.#tokens;
    }
}
